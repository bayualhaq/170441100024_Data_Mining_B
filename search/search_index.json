{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Data Mining \u00b6 Pengertian Data Mining menurut para ahli \u00b6 Secara sederhana data mining adalah penambangan atau penemuan informasi baru dengan mencari pola atau aturan tertentu dari sejumlah data yang sangat besar (Davies, 2004). Data Mining adalah proses yang menggunakan teknik statistik, matematika, kecerdasan buatan, machine learning untuk mengekstraksi dan mengidentifikasi informasi yang bermanfaat dan pengetahuan yang terkait dari berbagai database besar (Turban dkk. 2005). Data mining adalah kegiatan menemukan pola yang menarik dari data dalam jumlah besar, data dapat disimpan dalam database, data warehouse, atau penyimpanan informasi lainnya. Data mining berkaitan dengan bidang ilmu \u2013 ilmu lain, seperti database system, data warehousing, statistik, machine learning, information retrieval, dan komputasi tingkat tinggi. Selain itu, data mining didukung oleh ilmu lain seperti neural network, pengenalan pola, spatial data analysis, image database, signal processing (Han, 2006). Data mining juga disebut sebagai serangkaian proses untuk menggali nilai tambah berupa pengetahuan yang selama ini tidak diketahui secara manual dari suatu kumpulan data (Pramudiono, 2007). Karakteristik data mining \u00b6 Data mining berhubungan dengan penemuan sesuatu yang tersembunyi dan pola data tertentu yang tidak diketahui sebelumnya. Data mining biasa menggunakan data yang sangat besar. Biasanya data yang besar digunakan untuk membuat hasil lebih dipercaya. Data mining berguna untuk membuat keputusan yang kritis, terutama dalam strategi (Davies, 2004). Tahap-tahap data mining \u00b6 1. Data selection \u00b6 Pemilihan (seleksi) data dari sekumpulan data operasional perlu dilakukan sebelum tahap penggalian informasi dalam KDD dimulai. Data hasil seleksi yang digunakan untuk proses data mining, disimpan dalam suatu berkas, terpisah dari basis data operasional. 2. Pre-processing / cleaning \u00b6 Sebelum proses data mining dapat dilaksanakan, perlu dilakukan proses cleaning pada data yang menjadi fokus KDD. Proses cleaning mencakup antara lain membuang duplikasi data, memeriksa data yang inkonsisten, dan memperbaiki kesalahan pada data. 3. Transformation \u00b6 Coding adalah proses transformasi pada data yang telah dipilih, sehingga data tersebut sesuai untuk proses data mining. Proses coding dalam KDD merupakan proses kreatif dan sangat tergantung pada jenis atau pola informasi yang akan dicari dalam basis data. 4. Data mining \u00b6 Data mining adalah proses mencari pola atau informasi menarik dalam data terpilih dengan menggunakan teknik atau metode tertentu. Teknik, metode, atau algoritma dalam data mining sangat bervariasi. Pemilihan metode atau algoritma yang tepat sangat bergantung pada tujuan dan proses KDD secara keseluruhan. 5. Interpretation / evalution \u00b6 Pola informasi yang dihasilkan dari proses data mining perlu ditampilkan dalam bentuk yang mudah dimengerti oleh pihak yang berkepentingan. Tahap ini merupakan bagian dari proses KDD yang disebut interpretation. Tahap ini mencakup pemeriksaan apakah pola atau informasi yang ditemukan bertentangan dengan fakta atau hipotesis yang ada sebelumnya. Referensi \u00b6 Turban, E, 2005, Decision Support Systems and Intelligent Systems Edisi Bahasa Indonesia Jilid 1 . Andi: Yogyakarta. Larose, Daniel T. 2005. Discovering Knowledge in Data : An Introduction to Data Mining . John Willey & Sons, Inc. ayyad, Usama. 1996. Advances in Knowledge Discovery and Data Mining . MIT Press.","title":"Pengertian"},{"location":"#data-mining","text":"","title":"Data Mining"},{"location":"#pengertian-data-mining-menurut-para-ahli","text":"Secara sederhana data mining adalah penambangan atau penemuan informasi baru dengan mencari pola atau aturan tertentu dari sejumlah data yang sangat besar (Davies, 2004). Data Mining adalah proses yang menggunakan teknik statistik, matematika, kecerdasan buatan, machine learning untuk mengekstraksi dan mengidentifikasi informasi yang bermanfaat dan pengetahuan yang terkait dari berbagai database besar (Turban dkk. 2005). Data mining adalah kegiatan menemukan pola yang menarik dari data dalam jumlah besar, data dapat disimpan dalam database, data warehouse, atau penyimpanan informasi lainnya. Data mining berkaitan dengan bidang ilmu \u2013 ilmu lain, seperti database system, data warehousing, statistik, machine learning, information retrieval, dan komputasi tingkat tinggi. Selain itu, data mining didukung oleh ilmu lain seperti neural network, pengenalan pola, spatial data analysis, image database, signal processing (Han, 2006). Data mining juga disebut sebagai serangkaian proses untuk menggali nilai tambah berupa pengetahuan yang selama ini tidak diketahui secara manual dari suatu kumpulan data (Pramudiono, 2007).","title":"Pengertian Data Mining menurut para ahli"},{"location":"#karakteristik-data-mining","text":"Data mining berhubungan dengan penemuan sesuatu yang tersembunyi dan pola data tertentu yang tidak diketahui sebelumnya. Data mining biasa menggunakan data yang sangat besar. Biasanya data yang besar digunakan untuk membuat hasil lebih dipercaya. Data mining berguna untuk membuat keputusan yang kritis, terutama dalam strategi (Davies, 2004).","title":"Karakteristik data mining"},{"location":"#tahap-tahap-data-mining","text":"","title":"Tahap-tahap data mining"},{"location":"#1-data-selection","text":"Pemilihan (seleksi) data dari sekumpulan data operasional perlu dilakukan sebelum tahap penggalian informasi dalam KDD dimulai. Data hasil seleksi yang digunakan untuk proses data mining, disimpan dalam suatu berkas, terpisah dari basis data operasional.","title":"1. Data selection"},{"location":"#2-pre-processing-cleaning","text":"Sebelum proses data mining dapat dilaksanakan, perlu dilakukan proses cleaning pada data yang menjadi fokus KDD. Proses cleaning mencakup antara lain membuang duplikasi data, memeriksa data yang inkonsisten, dan memperbaiki kesalahan pada data.","title":"2. Pre-processing / cleaning"},{"location":"#3-transformation","text":"Coding adalah proses transformasi pada data yang telah dipilih, sehingga data tersebut sesuai untuk proses data mining. Proses coding dalam KDD merupakan proses kreatif dan sangat tergantung pada jenis atau pola informasi yang akan dicari dalam basis data.","title":"3. Transformation"},{"location":"#4-data-mining","text":"Data mining adalah proses mencari pola atau informasi menarik dalam data terpilih dengan menggunakan teknik atau metode tertentu. Teknik, metode, atau algoritma dalam data mining sangat bervariasi. Pemilihan metode atau algoritma yang tepat sangat bergantung pada tujuan dan proses KDD secara keseluruhan.","title":"4. Data mining"},{"location":"#5-interpretation-evalution","text":"Pola informasi yang dihasilkan dari proses data mining perlu ditampilkan dalam bentuk yang mudah dimengerti oleh pihak yang berkepentingan. Tahap ini merupakan bagian dari proses KDD yang disebut interpretation. Tahap ini mencakup pemeriksaan apakah pola atau informasi yang ditemukan bertentangan dengan fakta atau hipotesis yang ada sebelumnya.","title":"5. Interpretation / evalution"},{"location":"#referensi","text":"Turban, E, 2005, Decision Support Systems and Intelligent Systems Edisi Bahasa Indonesia Jilid 1 . Andi: Yogyakarta. Larose, Daniel T. 2005. Discovering Knowledge in Data : An Introduction to Data Mining . John Willey & Sons, Inc. ayyad, Usama. 1996. Advances in Knowledge Discovery and Data Mining . MIT Press.","title":"Referensi"},{"location":"Decision Tree/","text":"Decision Tree \u00b6 Pengertian Decision Tree \u00b6 Decision tree atau pohon keputusan adalah alat pendukung keputusan yang menggunakan model keputusan yang berbentuk seperti pohon. Decision tree memetakan berbagai alternatif yang mungkin untuk mengatasi suatu masalah, dan terdapat juga faktor-faktor kemungkinan yang dapat mempengaruhi alternatif tersebut beserta estimasi akhirnya jika memilih alternatif yang ada. Decision tree merupakan salah satu metode yang bisa digunakan untuk menampilkan algoritma dimana hanya berisi pernyataan kontrol bersyarat. Penggunaan Decision tree ini umunya dalam riset operasi, khususnya dalam analisis keputusan. Tujuan dalam menggunakan Decision tree untuk membantu mengidentifikasi strategi yang paling mungkin untuk mencapai tujuan dan merupakan alat yang populer dalam machine learning. Decision tree merupakan struktur seperti bagan alur dimana setiap simpul internal mewakili kemungkinan yang ada pada atribut, setiap cabang mewakili hasil dari kemungkinan tersebut, dan setiap simpul daun mewakili label kelas (keputusan diambil setelah menghitung semua atribut). Jalur dari root ke daun mewakili aturan klasifikasi. Struktur Decision tree \u00b6 Decision tree dibentuk dari 3 tipe dari simpul: simpul root, simpul perantara, dan simpul leaf. Simpul leaf memuat suatu keputusan akhir atau kelas target untuk suatu pohon keputusan. Simpul root adalah titik awal dari suatu decision tree. Setiap simpul perantara berhubungan dengan suatu pertanyaan atau pengujian Algoritma Decision Tree \u00b6 a. Pohon dibangun dalam suatu metoda rekursif topdown divide and-conquer. Seluruh contoh pelatihan dimulai dari simpul rootjalu dilakukan pengujian Mencabang ke jalur yang benar berdasarkan hasil pengujian. Apakah simpul leaf ditemukan? Jika yes, masukkan contoh ini ke kelas target, jika tidak kembali ke langkah 1. b. Atribut-atribut berada dalam suatu kategori (jika bernilai kontinu, nilai-nilai tersebut didiskritkan terlebih dahulu) c. Contoh-contoh dipartisi secara rekursif berdasarkan atribut terpilih d. Atribut-atribut uji dipilih berdasarkan heuristik atau pengukuran Statistik (misai, information gain). Rumus \u00b6 Rumus pencarian rata-rata entropy Kelebihan dan Kekurangan Decision Tree \u00b6 Kelebihan: Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik. Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka sample diuji hanya berdasarkan kriteria atau kelas tertentu. Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika menggunakan metode penghitungan satu tahap yang lebih konvensional Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan baik itu distribusi dimensi tinggi ataupun parameter tertentu dari distribusi kelas tersebut. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan. Kekurangan: Terjadi overlap terutama ketika kelas-kelas dan criteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan. Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar. Kesulitan dalam mendesain pohon keputusan yang optimal. Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain. Studi Kasus (Pima Indians) \u00b6 Pima Indians dengan Metode Algoritma Decision Tree Persiapan \u00b6 Python Version: 3.7.1 Pip Version: 19.1.1 Spyder Version: 3.3.2 Data yang digunakan yaitu Pima Indians Dataset yang diperoleh dari Kaggle.com https://github.com/bayualhaq/Bahan Berdasarkan Data Pima Indians Dataset dapat diketahui bahwa terdapat 392 data. Dalam data ini terdapat 9 variabel yaitu pregnant, glucose, diastolic, triceps, insulin, bmi, diabetes, age, test. Selanjutnya, Decision Tree dapat dilakukan dalam phyton seperti berikut. Langkah-langkah: \u00b6 1. Import Library \u00b6 Python package yang dibutuhkan dalam pembuatan program ini: import pandas as pd from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.tree import export_graphviz from sklearn.externals.six import StringIO from IPython.display import Image from sklearn import metrics import pydotplus import numpy as np 2. Import Data CVS ke python \u00b6 memasukkan data csv dari komputer ke python data = pd . read_csv ( 'PimaIndians.csv' ) 3. Menampilkan Informasi isi dari CSV \u00b6 menampilkan data data.head() output: pregnant glucose diastolic triceps ... bmi diabetes age test 0 1 89 66 23 ... 28.1 0.167 21 negatif 1 0 137 40 35 ... 43.1 2.288 33 positif 2 3 78 50 32 ... 31.0 0.248 26 positif 3 2 197 70 45 ... 30.5 0.158 53 positif 4 1 189 60 23 ... 30.1 0.398 59 positif 4. Menampilkan Informasi jenis type data tiap kolom \u00b6 data . info () Output: < class ' pandas . core . frame . DataFrame '> RangeIndex : 392 entries , 0 to 391 Data columns ( total 9 columns ): pregnant 392 non - null float64 glucose 392 non - null int64 diastolic 392 non - null int64 triceps 392 non - null int64 insulin 392 non - null int64 bmi 392 non - null float64 diabetes 392 non - null float64 age 392 non - null int64 test 392 non - null object dtypes : float64 ( 3 ), int64 ( 5 ), object ( 1 ) memory usage : 27.6 + KB 5. Memilih kolom uji untuk dihitung \u00b6 zero_not_accepted = [ 'pregnant' , 'glucose' , 'diastolic' , 'triceps' , 'insulin' , 'bmi' , 'diabetes' , 'age' ] # for col in zero_not_accepted: # for i in data[col]: # if i==0: # colSum = sum(data[col]) # meanCol=colSum/len(data[col]) # data[col]=meanCol for col in zero_not_accepted : data [ col ] = data [ col ] . replace ( 0 , np . NaN ) mean = int ( data [ col ] . mean ( skipna = True )) data [ col ] = data [ col ] . replace ( np . NaN , mean ) 6. Membagi data train dan data test dengan data test 30% \u00b6 X = data . iloc [:, 0 : 8 ] y = data . iloc [:, 8 ] X = data [[ 'pregnant' , 'glucose' , 'diastolic' , 'triceps' , 'insulin' , 'bmi' , 'diabetes' , 'age' ]] y = data [ 'test' ] #split data X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.3 , random_state = 0 ) 6. Menentukan Entropy \u00b6 # Create Decision Tree classifer object clf = DecisionTreeClassifier ( criterion = \"entropy\" , max_depth = 3 ) # Train Decision Tree Classifer clf = clf . fit ( X_train , y_train ) #Predict the response for test dataset y_pred = clf . predict ( X_test ) # Model Accuracy, how often is the classifier correct? print ( \"Accuracy:\" , metrics . accuracy_score ( y_test , y_pred )) output: Accuracy : 0.7711864406779662 Nilai akurasi 77.05% 7. Memvisualisasikan Pohon Keputusan \u00b6 feature_cols = [ 'pregnant' , 'glucose' , 'diastolic' , 'triceps' , 'insulin' , 'bmi' , 'diabetes' , 'age' ] dot_data = StringIO () export_graphviz ( clf , out_file = dot_data , filled = True , rounded = True , special_characters = True , feature_names = feature_cols , class_names = [ 'positif' , 'negatif' ]) graph = pydotplus . graph_from_dot_data ( dot_data . getvalue ()) graph . write_png ( 'diabetes.png' ) Image ( graph . create_png ()) Output: Referensi \u00b6 http://tessy.lecturer.pens.ac.id/kuliah/db2/klasifikasi.pdf https://fairuzelsaid.wordpress.com/2009/11/24/data-mining-konsep-pohon-keputusan https://www.datacamp.com/community/tutorials/decision-tree-classification-python","title":"Decision Tree"},{"location":"Decision Tree/#decision-tree","text":"","title":"Decision Tree"},{"location":"Decision Tree/#pengertian-decision-tree","text":"Decision tree atau pohon keputusan adalah alat pendukung keputusan yang menggunakan model keputusan yang berbentuk seperti pohon. Decision tree memetakan berbagai alternatif yang mungkin untuk mengatasi suatu masalah, dan terdapat juga faktor-faktor kemungkinan yang dapat mempengaruhi alternatif tersebut beserta estimasi akhirnya jika memilih alternatif yang ada. Decision tree merupakan salah satu metode yang bisa digunakan untuk menampilkan algoritma dimana hanya berisi pernyataan kontrol bersyarat. Penggunaan Decision tree ini umunya dalam riset operasi, khususnya dalam analisis keputusan. Tujuan dalam menggunakan Decision tree untuk membantu mengidentifikasi strategi yang paling mungkin untuk mencapai tujuan dan merupakan alat yang populer dalam machine learning. Decision tree merupakan struktur seperti bagan alur dimana setiap simpul internal mewakili kemungkinan yang ada pada atribut, setiap cabang mewakili hasil dari kemungkinan tersebut, dan setiap simpul daun mewakili label kelas (keputusan diambil setelah menghitung semua atribut). Jalur dari root ke daun mewakili aturan klasifikasi.","title":"Pengertian Decision Tree"},{"location":"Decision Tree/#struktur-decision-tree","text":"Decision tree dibentuk dari 3 tipe dari simpul: simpul root, simpul perantara, dan simpul leaf. Simpul leaf memuat suatu keputusan akhir atau kelas target untuk suatu pohon keputusan. Simpul root adalah titik awal dari suatu decision tree. Setiap simpul perantara berhubungan dengan suatu pertanyaan atau pengujian","title":"Struktur Decision tree"},{"location":"Decision Tree/#algoritma-decision-tree","text":"a. Pohon dibangun dalam suatu metoda rekursif topdown divide and-conquer. Seluruh contoh pelatihan dimulai dari simpul rootjalu dilakukan pengujian Mencabang ke jalur yang benar berdasarkan hasil pengujian. Apakah simpul leaf ditemukan? Jika yes, masukkan contoh ini ke kelas target, jika tidak kembali ke langkah 1. b. Atribut-atribut berada dalam suatu kategori (jika bernilai kontinu, nilai-nilai tersebut didiskritkan terlebih dahulu) c. Contoh-contoh dipartisi secara rekursif berdasarkan atribut terpilih d. Atribut-atribut uji dipilih berdasarkan heuristik atau pengukuran Statistik (misai, information gain).","title":"Algoritma Decision Tree"},{"location":"Decision Tree/#rumus","text":"Rumus pencarian rata-rata entropy","title":"Rumus"},{"location":"Decision Tree/#kelebihan-dan-kekurangan-decision-tree","text":"Kelebihan: Daerah pengambilan keputusan yang sebelumnya kompleks dan sangat global, dapat diubah menjadi lebih simpel dan spesifik. Eliminasi perhitungan-perhitungan yang tidak diperlukan, karena ketika menggunakan metode pohon keputusan maka sample diuji hanya berdasarkan kriteria atau kelas tertentu. Fleksibel untuk memilih fitur dari internal node yang berbeda, fitur yang terpilih akan membedakan suatu kriteria dibandingkan kriteria yang lain dalam node yang sama. Kefleksibelan metode pohon keputusan ini meningkatkan kualitas keputusan yang dihasilkan jika dibandingkan ketika menggunakan metode penghitungan satu tahap yang lebih konvensional Dalam analisis multivariat, dengan kriteria dan kelas yang jumlahnya sangat banyak, seorang penguji biasanya perlu untuk mengestimasikan baik itu distribusi dimensi tinggi ataupun parameter tertentu dari distribusi kelas tersebut. Metode pohon keputusan dapat menghindari munculnya permasalahan ini dengan menggunakan criteria yang jumlahnya lebih sedikit pada setiap node internal tanpa banyak mengurangi kualitas keputusan yang dihasilkan. Kekurangan: Terjadi overlap terutama ketika kelas-kelas dan criteria yang digunakan jumlahnya sangat banyak. Hal tersebut juga dapat menyebabkan meningkatnya waktu pengambilan keputusan dan jumlah memori yang diperlukan. Pengakumulasian jumlah eror dari setiap tingkat dalam sebuah pohon keputusan yang besar. Kesulitan dalam mendesain pohon keputusan yang optimal. Hasil kualitas keputusan yang didapatkan dari metode pohon keputusan sangat tergantung pada bagaimana pohon tersebut didesain.","title":"Kelebihan dan Kekurangan Decision Tree"},{"location":"Decision Tree/#studi-kasus-pima-indians","text":"Pima Indians dengan Metode Algoritma Decision Tree","title":"Studi Kasus (Pima Indians)"},{"location":"Decision Tree/#persiapan","text":"Python Version: 3.7.1 Pip Version: 19.1.1 Spyder Version: 3.3.2 Data yang digunakan yaitu Pima Indians Dataset yang diperoleh dari Kaggle.com https://github.com/bayualhaq/Bahan Berdasarkan Data Pima Indians Dataset dapat diketahui bahwa terdapat 392 data. Dalam data ini terdapat 9 variabel yaitu pregnant, glucose, diastolic, triceps, insulin, bmi, diabetes, age, test. Selanjutnya, Decision Tree dapat dilakukan dalam phyton seperti berikut.","title":"Persiapan"},{"location":"Decision Tree/#langkah-langkah","text":"","title":"Langkah-langkah:"},{"location":"Decision Tree/#1-import-library","text":"Python package yang dibutuhkan dalam pembuatan program ini: import pandas as pd from sklearn.tree import DecisionTreeClassifier from sklearn.model_selection import train_test_split from sklearn.tree import export_graphviz from sklearn.externals.six import StringIO from IPython.display import Image from sklearn import metrics import pydotplus import numpy as np","title":"1. Import Library"},{"location":"Decision Tree/#2-import-data-cvs-ke-python","text":"memasukkan data csv dari komputer ke python data = pd . read_csv ( 'PimaIndians.csv' )","title":"2. Import Data CVS ke python"},{"location":"Decision Tree/#3-menampilkan-informasi-isi-dari-csv","text":"menampilkan data data.head() output: pregnant glucose diastolic triceps ... bmi diabetes age test 0 1 89 66 23 ... 28.1 0.167 21 negatif 1 0 137 40 35 ... 43.1 2.288 33 positif 2 3 78 50 32 ... 31.0 0.248 26 positif 3 2 197 70 45 ... 30.5 0.158 53 positif 4 1 189 60 23 ... 30.1 0.398 59 positif","title":"3. Menampilkan Informasi isi dari CSV"},{"location":"Decision Tree/#4-menampilkan-informasi-jenis-type-data-tiap-kolom","text":"data . info () Output: < class ' pandas . core . frame . DataFrame '> RangeIndex : 392 entries , 0 to 391 Data columns ( total 9 columns ): pregnant 392 non - null float64 glucose 392 non - null int64 diastolic 392 non - null int64 triceps 392 non - null int64 insulin 392 non - null int64 bmi 392 non - null float64 diabetes 392 non - null float64 age 392 non - null int64 test 392 non - null object dtypes : float64 ( 3 ), int64 ( 5 ), object ( 1 ) memory usage : 27.6 + KB","title":"4. Menampilkan Informasi jenis type data tiap kolom"},{"location":"Decision Tree/#5-memilih-kolom-uji-untuk-dihitung","text":"zero_not_accepted = [ 'pregnant' , 'glucose' , 'diastolic' , 'triceps' , 'insulin' , 'bmi' , 'diabetes' , 'age' ] # for col in zero_not_accepted: # for i in data[col]: # if i==0: # colSum = sum(data[col]) # meanCol=colSum/len(data[col]) # data[col]=meanCol for col in zero_not_accepted : data [ col ] = data [ col ] . replace ( 0 , np . NaN ) mean = int ( data [ col ] . mean ( skipna = True )) data [ col ] = data [ col ] . replace ( np . NaN , mean )","title":"5. Memilih kolom uji untuk dihitung"},{"location":"Decision Tree/#6-membagi-data-train-dan-data-test-dengan-data-test-30","text":"X = data . iloc [:, 0 : 8 ] y = data . iloc [:, 8 ] X = data [[ 'pregnant' , 'glucose' , 'diastolic' , 'triceps' , 'insulin' , 'bmi' , 'diabetes' , 'age' ]] y = data [ 'test' ] #split data X_train , X_test , y_train , y_test = train_test_split ( X , y , test_size = 0.3 , random_state = 0 )","title":"6. Membagi data train dan data test dengan data test 30%"},{"location":"Decision Tree/#6-menentukan-entropy","text":"# Create Decision Tree classifer object clf = DecisionTreeClassifier ( criterion = \"entropy\" , max_depth = 3 ) # Train Decision Tree Classifer clf = clf . fit ( X_train , y_train ) #Predict the response for test dataset y_pred = clf . predict ( X_test ) # Model Accuracy, how often is the classifier correct? print ( \"Accuracy:\" , metrics . accuracy_score ( y_test , y_pred )) output: Accuracy : 0.7711864406779662 Nilai akurasi 77.05%","title":"6. Menentukan Entropy"},{"location":"Decision Tree/#7-memvisualisasikan-pohon-keputusan","text":"feature_cols = [ 'pregnant' , 'glucose' , 'diastolic' , 'triceps' , 'insulin' , 'bmi' , 'diabetes' , 'age' ] dot_data = StringIO () export_graphviz ( clf , out_file = dot_data , filled = True , rounded = True , special_characters = True , feature_names = feature_cols , class_names = [ 'positif' , 'negatif' ]) graph = pydotplus . graph_from_dot_data ( dot_data . getvalue ()) graph . write_png ( 'diabetes.png' ) Image ( graph . create_png ()) Output:","title":"7. Memvisualisasikan Pohon Keputusan"},{"location":"Decision Tree/#referensi","text":"http://tessy.lecturer.pens.ac.id/kuliah/db2/klasifikasi.pdf https://fairuzelsaid.wordpress.com/2009/11/24/data-mining-konsep-pohon-keputusan https://www.datacamp.com/community/tutorials/decision-tree-classification-python","title":"Referensi"},{"location":"K-Nearest Neighbors/","text":"K-Nearest Neighbors \u00b6 Pengertian Algoritma K-Nearest Neighbors \u00b6 K-nearest neighbors atau knn adalah algoritma yang berfungsi untuk melakukan klasifikasi suatu data berdasarkan data pembelajaran ( train data sets ), yang diambil dari k tetangga terdekatnya ( nearest neighbors ). Dengan k merupakan banyaknya tetangga terdekat. Cara Kerja Algoritma K-Nearest Neighbors (KNN) \u00b6 K-nearest neighbors melakukan klasifikasi dengan proyeksi data pembelajaran pada ruang berdimensi banyak. Ruang ini dibagi menjadi bagian-bagian yang merepresentasikan kriteria data pembelajaran. Setiap data pembelajaran direpresentasikan menjadi titik-titik c pada ruang dimensi banyak. Data baru yang diklasifikasi selanjutnya diproyeksikan pada ruang dimensi banyak yang telah memuat titik-titik c data pembelajaran. Proses klasifikasi dilakukan dengan mencari titik c terdekat dari c-baru ( nearest neighbor ) . Teknik pencarian tetangga terdekat yang umum dilakukan dengan menggunakan formula jarak euclidean. Berikut beberapa formula yang digunakan dalam algoritma knn. Euclidean Distance adalah formula untuk mencari jarak antara 2 titik dalam ruang dua dimensi. Hamming Distance adalah cara mencari jarak antar 2 titik yang dihitung dengan panjang vektor biner yang dibentuk oleh dua titik tersebut dalam block kode biner. Manhattan Distance adalah formula untuk mencari jarak d antar 2 vektor p,q pada ruang dimensi n . Minkowski Distance adalah formula pengukuran antar 2 titik pada ruang vektor normal yang merupakan hibridisasi yang mengeneralisasi euclidean distance dan mahattan distance. Teknik pencarian tetangga terdekat disesuaikan dengan dimensi data, proyeksi, dan kemudahan implementasi oleh pengguna. Tahapan Langkah Algoritma K-NN \u00b6 Menentukan parameter k (jumlah tetangga paling dekat). Menghitung kuadrat jarak eucliden objek terhadap data training yang diberikan. Mengurutkan hasil no 2 secara ascending (berurutan dari nilai tinggi ke rendah) Mengumpulkan kategori Y (Klasifikasi nearest neighbor berdasarkan nilai k) Dengan menggunakan kategori nearest neighbor yang paling mayoritas maka dapat dipredisikan kategori objek. Kelebihan dan Kekurangan K-Nearest Neighbors \u00b6 Kelebihan: Lebih efektif di data training yang besar Dapat menghasilkan data yang lebih akurat Mudah dipahami dan diimplementasikan Kekurangan: Perlu menunjukkan parameter K (jumlah tetangga terdekat) Tidak menangani nilai hilang (missing value) secara implisit Studi Kasus (Pima Indians) \u00b6 Pima Indians dengan Metode Algoritma K-Nearest Neighbors (KNN) Persiapan \u00b6 Python Version: 3.7.1 Pip Version: 19.1.1 Spyder Version: 3.3.2 Data yang digunakan yaitu Pima Indians Dataset yang diperoleh dari Kaggle.com https://github.com/bayualhaq/Bahan Berdasarkan Data Pima Indians Dataset dapat diketahui bahwa terdapat 392 data. Dalam data ini terdapat 9 variabel yaitu pregnant, glucose, diastolic, triceps, insulin, bmi, diabetes, age, test. Selanjutnya, klasifikasi menggunakan K-Nearest Neighbor dapat dilakukan dalam phyton seperti berikut. Langkah-langkah: \u00b6 1. Import Library \u00b6 Python package yang dibutuhkan dalam pembuatan program ini: import math import pandas as pd import matplotlib.pyplot as plt 2. Import Data CVS ke python \u00b6 memasukkan data csv dari komputer ke python dataset = pd . read_csv ( 'PimaIndians.csv' ) 3. Mengambil Kolom Data dari CSV \u00b6 col_pre = dataset . iloc [:, 0 ] . values #mengambil kolom 1 dari excel (pregnant) col_glu = dataset . iloc [:, 1 ] . values #mengambil kolom 2 dari excel (glucose) col_dias = dataset . iloc [:, 2 ] . values #mengambil kolom 3 dari excel (diastilic) col_tri = dataset . iloc [:, 3 ] . values #mengambil kolom 4 dari excel (triceps) col_ins = dataset . iloc [:, 4 ] . values #mengambil kolom 5 dari excel (insulin) col_ins = dataset . iloc [:, 5 ] . values #mengambil kolom 6 dari excel (bmi) col_bmi = dataset . iloc [:, 6 ] . values #mengambil kolom 7 dari excel (diabetes) col_glu = dataset . iloc [:, 7 ] . values #mengambil kolom 8 dari excel (age) col_test = dataset . iloc [:, 8 ] . values #mengambil kolom 9 dari excel (test) 4. Membuat Inputan nilai K \u00b6 user dapat memasukkan inputan nilai K sesuai dengan keinginan knn = int ( input ( \"Masukkan Nilai K = \" )) Output: Masukkan Nilai K = 5 5. Membuat Variable kosong untuk menyimpan nilai \u00b6 variable untuk menyimpan nilai data train pre = [] glu = [] dias = [] tri = [] ins = [] bmi = [] diab = [] age = [] test = [] variable untuk menyimpan nilai data tes pre_dt = [] glu_dt = [] dias_dt = [] tri_dt = [] ins_dt = [] bmi_dt = [] diab_dt = [] age_dt = [] test_dt = [] variable untuk menyimpan nilai hasil perhitungan Hasil = [] benar = [] data = [] accuracy = [] knn_graf = [] 6. Membuat Fungsi Data Train Class 0 \u00b6 fungsi mengambil data train yang mempunyai nilai class 0 dengan nama masuk_data_train_0 def masuk_data_train_0 ( data , masuk ): a = 0 for i in range ( len ( data )): if ( col_test [ i ] == 0 and a < 26 ): masuk . append ( data [ i ]) a = a + 1 7. Membuat Fungsi Data Train Class 1 \u00b6 fungsi mengambil data train yang mempunyai nilai class 1 dengan nama masuk_data_train_1 def masuk_data_train_1 ( data , masuk ): a = 0 for i in range ( len ( data )): if ( col_test [ i ] == 1 and a < 13 ): masuk . append ( data [ i ]) a = a + 1 8. Membuat Fungsi Data Test Class 0 \u00b6 fungsi mengambil data tes yang mempunyai nilai class 0 dengan nama masuk_data_test_0 def masuk_data_test_0 ( data , masuk ): a = 0 for i in range ( len ( data )): if ( col_test [ i ] == 0 ): a += 1 if ( a > 26 ): masuk . append ( data [ i ]) 9. Membuat Fungsi Data Test Class 1 \u00b6 fungsi mengambil data tes yang mempunyai nilai class 1 dengan nama masuk_data_test_1 def masuk_data_test_1 ( data , masuk ): a = 0 for i in range ( len ( data )): if ( col_test [ i ] == 1 ): a += 1 if ( a > 13 ): masuk . append ( data [ i ]) 10.Membuat Fungsi pcx \u00b6 fungsi mengambil data dari beberapa variable data train, data tes, knn def pcx ( data1 , data2 , data3 , data4 , data5 , data6 , data7 , data8 , data9 , dt1 , dt2 , dt3 , dt4 , dt5 , dt6 , dt7 , dt8 , dt9 , k , out ): membuat perulangan untuk menghitung jarak dari data asli dengan data tes for i in range ( len ( dt1 )): dist1 = [] test = [] coba = 0 for a in range ( len ( data1 )): dist = math . sqrt ( (( data1 [ a ] - dt1 [ i ]) ** 2 ) + (( data2 [ a ] - dt2 [ i ]) ** 2 ) + (( data3 [ a ] - dt3 [ i ]) ** 2 ) + (( data4 [ a ] - dt4 [ i ]) ** 2 ) + (( data5 [ a ] - dt5 [ i ]) ** 2 ) + (( data6 [ a ] - dt6 [ i ]) ** 2 ) + (( data7 [ a ] - dt7 [ i ]) ** 2 ) + (( data8 [ a ] - dt8 [ i ]) ** 2 )) dist1 . append ( dist ) dist1 , test = zip ( * sorted ( zip ( dist1 , data9 ))) for z in range ( k ): if ( test [ z ] == 0 ) : coba += 1 if (( z / 2 ) <= coba ): a = 0 out . append ( a ) else : a = 1 out . append ( a ) del dist1 del test coba = 0 11. Membuat Fungsi hasil \u00b6 fungsi ini digunakan untuk menghitung kebenaran data, jumlah data dan ke akurasian data def hasil ( data_asli , data_perbandingan , out , out2 , out3 ): a = 0 for x in range ( len ( data_asli )): if ( data_asli [ x ] == data_perbandingan [ x ]): a += 1 out . append ( a ) out2 . append ( 353 ) out3 . append ( a / 353 ) 12. Memasukkan data ke fungsi masuk_data_train_0 \u00b6 memasukkan data train mempunyai nilai class 0 masuk_data_train_0 ( col_pre , pre ) masuk_data_train_0 ( col_glu , glu ) masuk_data_train_0 ( col_dias , dias ) masuk_data_train_0 ( col_tri , tri ) masuk_data_train_0 ( col_ins , ins ) masuk_data_train_0 ( col_ins , bmi ) masuk_data_train_0 ( col_bmi , diab ) masuk_data_train_0 ( col_glu , age ) masuk_data_train_0 ( col_test , test ) 13. Memasukkan data ke fungsi masuk_data_train_1 \u00b6 memasukkan data train mempunyai nilai class 1 masuk_data_train_1 ( col_pre , pre ) masuk_data_train_1 ( col_glu , glu ) masuk_data_train_1 ( col_dias , dias ) masuk_data_train_1 ( col_tri , tri ) masuk_data_train_1 ( col_ins , ins ) masuk_data_train_1 ( col_ins , bmi ) masuk_data_train_1 ( col_bmi , diab ) masuk_data_train_1 ( col_glu , age ) masuk_data_train_1 ( col_test , test ) 14. Memasukkan data ke fungsi masuk_data_test_0 \u00b6 memasukkan data tes mempunyai nilai class 1 masuk_data_test_0 ( col_pre , pre_dt ) masuk_data_test_0 ( col_glu , glu_dt ) masuk_data_test_0 ( col_dias , dias_dt ) masuk_data_test_0 ( col_tri , tri_dt ) masuk_data_test_0 ( col_ins , ins_dt ) masuk_data_test_0 ( col_ins , bmi_dt ) masuk_data_test_0 ( col_bmi , diab_dt ) masuk_data_test_0 ( col_glu , age_dt ) masuk_data_test_0 ( col_test , test_dt ) 15. Memasukkan data ke fungsi masuk_data_test_1 \u00b6 memasukkan data train mempunyai nilai class 1 masuk_data_test_1(col_pre,pre_dt) masuk_data_test_1(col_glu,glu_dt) masuk_data_test_1(col_dias,dias_dt) masuk_data_test_1(col_tri,tri_dt) masuk_data_test_1(col_ins,ins_dt) masuk_data_test_1(col_ins,bmi_dt) masuk_data_test_1(col_bmi,diab_dt) masuk_data_test_1(col_glu,age_dt) masuk_data_test_1(col_test,test_dt) 16. Membuat perulangan KNN \u00b6 for knnn in range ( knn - 1 ): knnn += 2 del Hasil Hasil = [] 17. Memasukkan data train, data tes ke fungsi pcx \u00b6 pcx ( pre , glu , dias , tri , ins , bmi , diab , age , test , pre_dt , glu_dt , dias_dt , tri_dt , ins_dt , bmi_dt , diab_dt , age_dt , test_dt , knnn , Hasil ) 18. Memasukkan data Class \u00b6 kebenaran data, jumlah data dan ke akurasian data #test_dt yaitu data asli diambil dari kolom test #Hasil yaitu perhitungan data dari pcx sehingga menghasilkan nilai 0 dan nilai 1 #benar yaitu perhitungan setelah data dibandingan dengan data asli #data yaitu banyak nya data dari data tes #accuracy yaitu membagi benar dengan data sehingga mendapat nilai keakurasian hasil ( test_dt , Hasil , benar , data , accuracy ) 19. Membuat titik untuk grafik \u00b6 knn_graf . append ( knnn ) 20. Memasukkan data ke bentuk table \u00b6 df = pd . DataFrame ({ 'knn' : knn_graf , 'databenar' : benar , 'Jmldata' : data , 'accuracy' : accuracy }) print ( df ) Output: knn databenar Jmldata accuracy 0 2 236 353 0.668555 1 3 241 353 0.682720 2 4 240 353 0.679887 3 5 240 353 0.679887 21. Menampilkan data dalam bentuk grafik batang \u00b6 df . plot ( kind = 'line' , x = 'knn' , y = 'accuracy' , color = 'blue' ) plt . show () Output: Referensi \u00b6 https://www.advernesia.com/blog/data-science/pengertian-dan-cara-kerja-algoritma-k-nearest-neighbours-knn/ http://congryo.blogspot.com/2013/01/pengertian-kekurangan-dan-kelebihan.html https://medium.com/@16611130/klasifikasi-menggunakan-metode-knn-k-nearest-neighbor-dalam-python-a40e79a74101","title":"K-Nearest Neighbors"},{"location":"K-Nearest Neighbors/#k-nearest-neighbors","text":"","title":"K-Nearest Neighbors"},{"location":"K-Nearest Neighbors/#pengertian-algoritma-k-nearest-neighbors","text":"K-nearest neighbors atau knn adalah algoritma yang berfungsi untuk melakukan klasifikasi suatu data berdasarkan data pembelajaran ( train data sets ), yang diambil dari k tetangga terdekatnya ( nearest neighbors ). Dengan k merupakan banyaknya tetangga terdekat.","title":"Pengertian Algoritma K-Nearest Neighbors"},{"location":"K-Nearest Neighbors/#cara-kerja-algoritma-k-nearest-neighbors-knn","text":"K-nearest neighbors melakukan klasifikasi dengan proyeksi data pembelajaran pada ruang berdimensi banyak. Ruang ini dibagi menjadi bagian-bagian yang merepresentasikan kriteria data pembelajaran. Setiap data pembelajaran direpresentasikan menjadi titik-titik c pada ruang dimensi banyak. Data baru yang diklasifikasi selanjutnya diproyeksikan pada ruang dimensi banyak yang telah memuat titik-titik c data pembelajaran. Proses klasifikasi dilakukan dengan mencari titik c terdekat dari c-baru ( nearest neighbor ) . Teknik pencarian tetangga terdekat yang umum dilakukan dengan menggunakan formula jarak euclidean. Berikut beberapa formula yang digunakan dalam algoritma knn. Euclidean Distance adalah formula untuk mencari jarak antara 2 titik dalam ruang dua dimensi. Hamming Distance adalah cara mencari jarak antar 2 titik yang dihitung dengan panjang vektor biner yang dibentuk oleh dua titik tersebut dalam block kode biner. Manhattan Distance adalah formula untuk mencari jarak d antar 2 vektor p,q pada ruang dimensi n . Minkowski Distance adalah formula pengukuran antar 2 titik pada ruang vektor normal yang merupakan hibridisasi yang mengeneralisasi euclidean distance dan mahattan distance. Teknik pencarian tetangga terdekat disesuaikan dengan dimensi data, proyeksi, dan kemudahan implementasi oleh pengguna.","title":"Cara Kerja Algoritma K-Nearest Neighbors (KNN)"},{"location":"K-Nearest Neighbors/#tahapan-langkah-algoritma-k-nn","text":"Menentukan parameter k (jumlah tetangga paling dekat). Menghitung kuadrat jarak eucliden objek terhadap data training yang diberikan. Mengurutkan hasil no 2 secara ascending (berurutan dari nilai tinggi ke rendah) Mengumpulkan kategori Y (Klasifikasi nearest neighbor berdasarkan nilai k) Dengan menggunakan kategori nearest neighbor yang paling mayoritas maka dapat dipredisikan kategori objek.","title":"Tahapan Langkah Algoritma K-NN"},{"location":"K-Nearest Neighbors/#kelebihan-dan-kekurangan-k-nearest-neighbors","text":"Kelebihan: Lebih efektif di data training yang besar Dapat menghasilkan data yang lebih akurat Mudah dipahami dan diimplementasikan Kekurangan: Perlu menunjukkan parameter K (jumlah tetangga terdekat) Tidak menangani nilai hilang (missing value) secara implisit","title":"Kelebihan dan Kekurangan K-Nearest Neighbors"},{"location":"K-Nearest Neighbors/#studi-kasus-pima-indians","text":"Pima Indians dengan Metode Algoritma K-Nearest Neighbors (KNN)","title":"Studi Kasus (Pima Indians)"},{"location":"K-Nearest Neighbors/#persiapan","text":"Python Version: 3.7.1 Pip Version: 19.1.1 Spyder Version: 3.3.2 Data yang digunakan yaitu Pima Indians Dataset yang diperoleh dari Kaggle.com https://github.com/bayualhaq/Bahan Berdasarkan Data Pima Indians Dataset dapat diketahui bahwa terdapat 392 data. Dalam data ini terdapat 9 variabel yaitu pregnant, glucose, diastolic, triceps, insulin, bmi, diabetes, age, test. Selanjutnya, klasifikasi menggunakan K-Nearest Neighbor dapat dilakukan dalam phyton seperti berikut.","title":"Persiapan"},{"location":"K-Nearest Neighbors/#langkah-langkah","text":"","title":"Langkah-langkah:"},{"location":"K-Nearest Neighbors/#1-import-library","text":"Python package yang dibutuhkan dalam pembuatan program ini: import math import pandas as pd import matplotlib.pyplot as plt","title":"1. Import Library"},{"location":"K-Nearest Neighbors/#2-import-data-cvs-ke-python","text":"memasukkan data csv dari komputer ke python dataset = pd . read_csv ( 'PimaIndians.csv' )","title":"2. Import Data CVS ke python"},{"location":"K-Nearest Neighbors/#3-mengambil-kolom-data-dari-csv","text":"col_pre = dataset . iloc [:, 0 ] . values #mengambil kolom 1 dari excel (pregnant) col_glu = dataset . iloc [:, 1 ] . values #mengambil kolom 2 dari excel (glucose) col_dias = dataset . iloc [:, 2 ] . values #mengambil kolom 3 dari excel (diastilic) col_tri = dataset . iloc [:, 3 ] . values #mengambil kolom 4 dari excel (triceps) col_ins = dataset . iloc [:, 4 ] . values #mengambil kolom 5 dari excel (insulin) col_ins = dataset . iloc [:, 5 ] . values #mengambil kolom 6 dari excel (bmi) col_bmi = dataset . iloc [:, 6 ] . values #mengambil kolom 7 dari excel (diabetes) col_glu = dataset . iloc [:, 7 ] . values #mengambil kolom 8 dari excel (age) col_test = dataset . iloc [:, 8 ] . values #mengambil kolom 9 dari excel (test)","title":"3. Mengambil Kolom Data dari CSV"},{"location":"K-Nearest Neighbors/#4-membuat-inputan-nilai-k","text":"user dapat memasukkan inputan nilai K sesuai dengan keinginan knn = int ( input ( \"Masukkan Nilai K = \" )) Output: Masukkan Nilai K = 5","title":"4. Membuat Inputan nilai K"},{"location":"K-Nearest Neighbors/#5-membuat-variable-kosong-untuk-menyimpan-nilai","text":"variable untuk menyimpan nilai data train pre = [] glu = [] dias = [] tri = [] ins = [] bmi = [] diab = [] age = [] test = [] variable untuk menyimpan nilai data tes pre_dt = [] glu_dt = [] dias_dt = [] tri_dt = [] ins_dt = [] bmi_dt = [] diab_dt = [] age_dt = [] test_dt = [] variable untuk menyimpan nilai hasil perhitungan Hasil = [] benar = [] data = [] accuracy = [] knn_graf = []","title":"5. Membuat Variable kosong untuk menyimpan nilai"},{"location":"K-Nearest Neighbors/#6-membuat-fungsi-data-train-class-0","text":"fungsi mengambil data train yang mempunyai nilai class 0 dengan nama masuk_data_train_0 def masuk_data_train_0 ( data , masuk ): a = 0 for i in range ( len ( data )): if ( col_test [ i ] == 0 and a < 26 ): masuk . append ( data [ i ]) a = a + 1","title":"6. Membuat Fungsi Data Train Class 0"},{"location":"K-Nearest Neighbors/#7-membuat-fungsi-data-train-class-1","text":"fungsi mengambil data train yang mempunyai nilai class 1 dengan nama masuk_data_train_1 def masuk_data_train_1 ( data , masuk ): a = 0 for i in range ( len ( data )): if ( col_test [ i ] == 1 and a < 13 ): masuk . append ( data [ i ]) a = a + 1","title":"7. Membuat Fungsi Data Train Class 1"},{"location":"K-Nearest Neighbors/#8-membuat-fungsi-data-test-class-0","text":"fungsi mengambil data tes yang mempunyai nilai class 0 dengan nama masuk_data_test_0 def masuk_data_test_0 ( data , masuk ): a = 0 for i in range ( len ( data )): if ( col_test [ i ] == 0 ): a += 1 if ( a > 26 ): masuk . append ( data [ i ])","title":"8. Membuat Fungsi Data Test Class 0"},{"location":"K-Nearest Neighbors/#9-membuat-fungsi-data-test-class-1","text":"fungsi mengambil data tes yang mempunyai nilai class 1 dengan nama masuk_data_test_1 def masuk_data_test_1 ( data , masuk ): a = 0 for i in range ( len ( data )): if ( col_test [ i ] == 1 ): a += 1 if ( a > 13 ): masuk . append ( data [ i ])","title":"9. Membuat Fungsi Data Test Class 1"},{"location":"K-Nearest Neighbors/#10membuat-fungsi-pcx","text":"fungsi mengambil data dari beberapa variable data train, data tes, knn def pcx ( data1 , data2 , data3 , data4 , data5 , data6 , data7 , data8 , data9 , dt1 , dt2 , dt3 , dt4 , dt5 , dt6 , dt7 , dt8 , dt9 , k , out ): membuat perulangan untuk menghitung jarak dari data asli dengan data tes for i in range ( len ( dt1 )): dist1 = [] test = [] coba = 0 for a in range ( len ( data1 )): dist = math . sqrt ( (( data1 [ a ] - dt1 [ i ]) ** 2 ) + (( data2 [ a ] - dt2 [ i ]) ** 2 ) + (( data3 [ a ] - dt3 [ i ]) ** 2 ) + (( data4 [ a ] - dt4 [ i ]) ** 2 ) + (( data5 [ a ] - dt5 [ i ]) ** 2 ) + (( data6 [ a ] - dt6 [ i ]) ** 2 ) + (( data7 [ a ] - dt7 [ i ]) ** 2 ) + (( data8 [ a ] - dt8 [ i ]) ** 2 )) dist1 . append ( dist ) dist1 , test = zip ( * sorted ( zip ( dist1 , data9 ))) for z in range ( k ): if ( test [ z ] == 0 ) : coba += 1 if (( z / 2 ) <= coba ): a = 0 out . append ( a ) else : a = 1 out . append ( a ) del dist1 del test coba = 0","title":"10.Membuat Fungsi pcx"},{"location":"K-Nearest Neighbors/#11-membuat-fungsi-hasil","text":"fungsi ini digunakan untuk menghitung kebenaran data, jumlah data dan ke akurasian data def hasil ( data_asli , data_perbandingan , out , out2 , out3 ): a = 0 for x in range ( len ( data_asli )): if ( data_asli [ x ] == data_perbandingan [ x ]): a += 1 out . append ( a ) out2 . append ( 353 ) out3 . append ( a / 353 )","title":"11. Membuat Fungsi hasil"},{"location":"K-Nearest Neighbors/#12-memasukkan-data-ke-fungsi-masuk_data_train_0","text":"memasukkan data train mempunyai nilai class 0 masuk_data_train_0 ( col_pre , pre ) masuk_data_train_0 ( col_glu , glu ) masuk_data_train_0 ( col_dias , dias ) masuk_data_train_0 ( col_tri , tri ) masuk_data_train_0 ( col_ins , ins ) masuk_data_train_0 ( col_ins , bmi ) masuk_data_train_0 ( col_bmi , diab ) masuk_data_train_0 ( col_glu , age ) masuk_data_train_0 ( col_test , test )","title":"12. Memasukkan data ke fungsi masuk_data_train_0"},{"location":"K-Nearest Neighbors/#13-memasukkan-data-ke-fungsi-masuk_data_train_1","text":"memasukkan data train mempunyai nilai class 1 masuk_data_train_1 ( col_pre , pre ) masuk_data_train_1 ( col_glu , glu ) masuk_data_train_1 ( col_dias , dias ) masuk_data_train_1 ( col_tri , tri ) masuk_data_train_1 ( col_ins , ins ) masuk_data_train_1 ( col_ins , bmi ) masuk_data_train_1 ( col_bmi , diab ) masuk_data_train_1 ( col_glu , age ) masuk_data_train_1 ( col_test , test )","title":"13.  Memasukkan data ke fungsi masuk_data_train_1"},{"location":"K-Nearest Neighbors/#14-memasukkan-data-ke-fungsi-masuk_data_test_0","text":"memasukkan data tes mempunyai nilai class 1 masuk_data_test_0 ( col_pre , pre_dt ) masuk_data_test_0 ( col_glu , glu_dt ) masuk_data_test_0 ( col_dias , dias_dt ) masuk_data_test_0 ( col_tri , tri_dt ) masuk_data_test_0 ( col_ins , ins_dt ) masuk_data_test_0 ( col_ins , bmi_dt ) masuk_data_test_0 ( col_bmi , diab_dt ) masuk_data_test_0 ( col_glu , age_dt ) masuk_data_test_0 ( col_test , test_dt )","title":"14. Memasukkan data ke fungsi masuk_data_test_0"},{"location":"K-Nearest Neighbors/#15-memasukkan-data-ke-fungsi-masuk_data_test_1","text":"memasukkan data train mempunyai nilai class 1 masuk_data_test_1(col_pre,pre_dt) masuk_data_test_1(col_glu,glu_dt) masuk_data_test_1(col_dias,dias_dt) masuk_data_test_1(col_tri,tri_dt) masuk_data_test_1(col_ins,ins_dt) masuk_data_test_1(col_ins,bmi_dt) masuk_data_test_1(col_bmi,diab_dt) masuk_data_test_1(col_glu,age_dt) masuk_data_test_1(col_test,test_dt)","title":"15. Memasukkan data ke fungsi masuk_data_test_1"},{"location":"K-Nearest Neighbors/#16-membuat-perulangan-knn","text":"for knnn in range ( knn - 1 ): knnn += 2 del Hasil Hasil = []","title":"16. Membuat perulangan KNN"},{"location":"K-Nearest Neighbors/#17-memasukkan-data-train-data-tes-ke-fungsi-pcx","text":"pcx ( pre , glu , dias , tri , ins , bmi , diab , age , test , pre_dt , glu_dt , dias_dt , tri_dt , ins_dt , bmi_dt , diab_dt , age_dt , test_dt , knnn , Hasil )","title":"17. Memasukkan data train, data tes ke fungsi pcx"},{"location":"K-Nearest Neighbors/#18-memasukkan-data-class","text":"kebenaran data, jumlah data dan ke akurasian data #test_dt yaitu data asli diambil dari kolom test #Hasil yaitu perhitungan data dari pcx sehingga menghasilkan nilai 0 dan nilai 1 #benar yaitu perhitungan setelah data dibandingan dengan data asli #data yaitu banyak nya data dari data tes #accuracy yaitu membagi benar dengan data sehingga mendapat nilai keakurasian hasil ( test_dt , Hasil , benar , data , accuracy )","title":"18. Memasukkan data Class"},{"location":"K-Nearest Neighbors/#19-membuat-titik-untuk-grafik","text":"knn_graf . append ( knnn )","title":"19. Membuat titik untuk grafik"},{"location":"K-Nearest Neighbors/#20-memasukkan-data-ke-bentuk-table","text":"df = pd . DataFrame ({ 'knn' : knn_graf , 'databenar' : benar , 'Jmldata' : data , 'accuracy' : accuracy }) print ( df ) Output: knn databenar Jmldata accuracy 0 2 236 353 0.668555 1 3 241 353 0.682720 2 4 240 353 0.679887 3 5 240 353 0.679887","title":"20. Memasukkan data ke bentuk table"},{"location":"K-Nearest Neighbors/#21-menampilkan-data-dalam-bentuk-grafik-batang","text":"df . plot ( kind = 'line' , x = 'knn' , y = 'accuracy' , color = 'blue' ) plt . show () Output:","title":"21.  Menampilkan data dalam bentuk grafik batang"},{"location":"K-Nearest Neighbors/#referensi","text":"https://www.advernesia.com/blog/data-science/pengertian-dan-cara-kerja-algoritma-k-nearest-neighbours-knn/ http://congryo.blogspot.com/2013/01/pengertian-kekurangan-dan-kelebihan.html https://medium.com/@16611130/klasifikasi-menggunakan-metode-knn-k-nearest-neighbor-dalam-python-a40e79a74101","title":"Referensi"},{"location":"authors-notes/","text":"Author's notes \u00b6 Hi, I'm Bayu Al Haq \u00b6 Assalamualaikum Wr. Wb Perkenalkan, Saya Ahmad Try Bayu Al Haq (170441100024) mahasiswa Prodi Sistem Informasi'17 dari Universitas Trunojojyo Madura. Ini adalah beberapa project Data Mining mulai dari Metode Algoritma K-Nearest Neighbors (KNN) dan Decision Tree yang dibuat untuk memenuhi tugas mata kuliah Data Mining kelas B. Apabila ada penulisan yang kurang tepat saya mohon maaf Wassalamualaikum Wr. Wb","title":"Author's notes"},{"location":"authors-notes/#authors-notes","text":"","title":"Author's notes"},{"location":"authors-notes/#hi-im-bayu-al-haq","text":"Assalamualaikum Wr. Wb Perkenalkan, Saya Ahmad Try Bayu Al Haq (170441100024) mahasiswa Prodi Sistem Informasi'17 dari Universitas Trunojojyo Madura. Ini adalah beberapa project Data Mining mulai dari Metode Algoritma K-Nearest Neighbors (KNN) dan Decision Tree yang dibuat untuk memenuhi tugas mata kuliah Data Mining kelas B. Apabila ada penulisan yang kurang tepat saya mohon maaf Wassalamualaikum Wr. Wb","title":"Hi, I'm Bayu Al Haq"}]}